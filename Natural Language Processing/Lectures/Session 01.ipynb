{
 "cells": [
  {
   "cell_type": "raw",
   "id": "1ca48844",
   "metadata": {},
   "source": [
    "Date - 21/10/2021  11:00 AM to 01:00 PM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00f1397",
   "metadata": {},
   "source": [
    "# Introduction To Natural Language Processing\n",
    "\n",
    "    1). Natural language processing (NLP) is an area of computer science and artificial intelligence concerned with the\n",
    "        interaction between computers and humans in natural language.\n",
    "        \n",
    "    2). The ultimate goal of NLP is to help computers understand language as well as we do. It is the driving force behind\n",
    "        things like virtual assistants, speech recognition, sentiment analysis, automatic text summarization, machine\n",
    "        translation and much more.\n",
    "    \n",
    "    3). Applications of NLP techniques include voice assistants like Amazon's Alexa and Apple's Siri,but also things like\n",
    "        machine translation and text-filtering.\n",
    "    \n",
    "    4). Syntactic analysis (syntax) and semantic analysis (semantic) are the two primary techniques that lead to the\n",
    "        understanding of natural language.Language is a set of valid sentences,but what makes a sentence valid? Syntax and\n",
    "        semantics.\n",
    "\n",
    "    5). Syntax is the grammatical structure of the text, whereas semantics is the meaning being conveyed. A sentence that\n",
    "        is syntactically correct, however, is not always semantically correct. For example, “cows flow supremely” is\n",
    "        grammatically valid (subject — verb — adverb) but it doesn't make any sense.\n",
    "        \n",
    "    Semantic analysis is the process of understanding the meaning and interpretation of words, signs and sentence\n",
    "    structure. This lets computers partly understand natural language the way humans do. I say partly because semantic\n",
    "    analysis is one of the toughest parts of NLP and it's not fully solved yet.\n",
    "\n",
    "    Speech recognition, for example, has gotten very good and works almost flawlessly, but we still lack this kind of\n",
    "    proficiency in natural language understanding. Your phone basically understands what you have said, but often can’t do\n",
    "    anything with it because it doesn’t understand the meaning behind it. Also, some of the technologies out there only\n",
    "    make you think they understand the meaning of a text.\n",
    "\n",
    "    An approach based on keywords or statistics or even pure machine learning may be using a matching or frequency\n",
    "    technique for clues as to what the text is “about.” These methods are limited because they are not looking at the real\n",
    "    underlying meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad6ab9f",
   "metadata": {},
   "source": [
    "## What is NLTK?\n",
    "\n",
    "    NLTK is a standard python library with prebuilt functions and utilities for the ease of use and implementation. It is\n",
    "    one of the most used libraries for natural language processing and computational linguistics.\n",
    "    \n",
    "    It provides us various text processing libraries with a lot of test datasets.\n",
    "    \n",
    "    A variety of tasks can be performed using NLTK such as tokenizing, parse tree visualization, etc… In this article, we\n",
    "    will go through how we can set up NLTK in our system and use them for performing various NLP tasks during the text\n",
    "    processing step.\n",
    "    \n",
    "**To install nltk**\n",
    "\n",
    "    >!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15e71f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "585b9d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Abhi\n",
      "[nltk_data]     Kumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec378bf1",
   "metadata": {},
   "source": [
    "## Sentence Segmentation:\n",
    "\n",
    "    The first step in the pipeline is to break the text apart into separate sentences. That gives us this:\n",
    "    \n",
    "    “Mumbai or Bombay is the capital city of the Indian state of Maharashtra.”\n",
    "    “According to the United Nations, as of 2018, Mumbai was the second most populated city in India after Delhi.”\n",
    "    “In the world with a population of roughly 20 million.”\n",
    "\n",
    "    We can assume that each sentence in English is a separate thought or idea. It will be a lot easier to write a program\n",
    "    to understand a single sentence than to understand a whole paragraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "782c238f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Mumbai or Bombay is the capital city of the Indian state of Maharashtra. According to the United Nations, as of 2018, Mumbai was the second most populated city in India after Delhi. In the world with a population of roughly 20 million\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3fb6120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mumbai or Bombay is the capital city of the Indian state of Maharashtra. According to the United Nations, as of 2018, Mumbai was the second most populated city in India after Delhi. In the world with a population of roughly 20 million'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9462dc",
   "metadata": {},
   "source": [
    "### Using Sentence Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6515d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = nltk.sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6e56c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mumbai or Bombay is the capital city of the Indian state of Maharashtra.',\n",
       " 'According to the United Nations, as of 2018, Mumbai was the second most populated city in India after Delhi.',\n",
       " 'In the world with a population of roughly 20 million']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71adcc21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mumbai or Bombay is the capital city of the Indian state of Maharashtra.\n",
      "According to the United Nations, as of 2018, Mumbai was the second most populated city in India after Delhi.\n",
      "In the world with a population of roughly 20 million\n"
     ]
    }
   ],
   "source": [
    "for item in sentence:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f50125",
   "metadata": {},
   "source": [
    "**Tokenization is essentially splitting a phrase, sentence, paragraph, or an entire text document into smaller units, such as individual words or terms. Each of these smaller units are called tokens.**\n",
    "\n",
    "  `Natural Language Processing`\n",
    "\n",
    "`['Natural', 'Language', 'Processing']`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7206ae60",
   "metadata": {},
   "source": [
    "## Why is Tokenization required in NLP?\n",
    "\n",
    "    Think about the English language here. Pick up any sentence you can think of and hold that in your mind as you read\n",
    "    this section. This will help you understand the importance of tokenization in a much easier manner.\n",
    "\n",
    "    Before processing a natural language, we need to identify the words that constitute a string of characters. That’s why\n",
    "    tokenization is the most basic step to proceed with NLP (text data). This is important because the meaning of the text\n",
    "    could easily be interpreted by analyzing the words present in the text.\n",
    "\n",
    "    Let’s take an example. Consider the below string:\n",
    "\n",
    "    “This is a cat.”\n",
    "\n",
    "    What do you think will happen after we perform tokenization on this string? We get [‘This’, ‘is’, ‘a’, cat’].\n",
    "    \n",
    "    There are numerous uses of doing this. We can use this tokenized form to:\n",
    "    - Count the number of words in the text,\n",
    "    - Count the frequency of the word, that is, the number of times a particular word is present.\n",
    "\n",
    "**Tokenization using Python’s split() function**\n",
    "    \n",
    "    Let’s start with the split() method as it is the most basic one. It returns a list of strings after breaking the given\n",
    "    string by the specified separator. By default, split() breaks a string at each space. We can change the separator to\n",
    "    anything.\n",
    "    \n",
    "    Let’s check it out in the programming example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5b31b9",
   "metadata": {},
   "source": [
    "### Using Split Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4170ae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = \"This is a cat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e67efa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'is', 'a', 'cat']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa7555b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "val1 = \"This is. a, cat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "050ee551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is. a, cat']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val1.split(' .,')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e613af52",
   "metadata": {},
   "source": [
    "### Using Regular Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b33a4c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "    Founded in 1991 Python Programming was built to give users a easier way of writing code.\n",
    "    In the Intial day's Python was considered a slow programming language.\n",
    "    Later Many Improvements were made by updating the language.\n",
    "    And today it has more than 3 lakh librarys available.\n",
    "    Currently used in Data Related Field Heavily.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31274ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n    Founded in 1991 Python Programming was built to give users a easier way of writing code.\\n    In the Intial day's Python was considered a slow programming language.\\n    Later Many Improvements were made by updating the language.\\n    And today it has more than 3 lakh librarys available.\\n    Currently used in Data Related Field Heavily.\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04fec041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22d1bcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = re.findall(\"[\\w]+\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6695615e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Founded',\n",
       " 'in',\n",
       " '1991',\n",
       " 'Python',\n",
       " 'Programming',\n",
       " 'was',\n",
       " 'built',\n",
       " 'to',\n",
       " 'give',\n",
       " 'users',\n",
       " 'a',\n",
       " 'easier',\n",
       " 'way',\n",
       " 'of',\n",
       " 'writing',\n",
       " 'code',\n",
       " 'In',\n",
       " 'the',\n",
       " 'Intial',\n",
       " 'day',\n",
       " 's',\n",
       " 'Python',\n",
       " 'was',\n",
       " 'considered',\n",
       " 'a',\n",
       " 'slow',\n",
       " 'programming',\n",
       " 'language',\n",
       " 'Later',\n",
       " 'Many',\n",
       " 'Improvements',\n",
       " 'were',\n",
       " 'made',\n",
       " 'by',\n",
       " 'updating',\n",
       " 'the',\n",
       " 'language',\n",
       " 'And',\n",
       " 'today',\n",
       " 'it',\n",
       " 'has',\n",
       " 'more',\n",
       " 'than',\n",
       " '3',\n",
       " 'lakh',\n",
       " 'librarys',\n",
       " 'available',\n",
       " 'Currently',\n",
       " 'used',\n",
       " 'in',\n",
       " 'Data',\n",
       " 'Related',\n",
       " 'Field',\n",
       " 'Heavily']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "070df289",
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = re.compile('[.]').split(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c49d10fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n    Founded in 1991 Python Programming was built to give users a easier way of writing code',\n",
       " \"\\n    In the Intial day's Python was considered a slow programming language\",\n",
       " '\\n    Later Many Improvements were made by updating the language',\n",
       " '\\n    And today it has more than 3 lakh librarys available',\n",
       " '\\n    Currently used in Data Related Field Heavily',\n",
       " '\\n']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04f5a9e",
   "metadata": {},
   "source": [
    "### Using Word Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "432e59b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14f5c385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Founded',\n",
       " 'in',\n",
       " '1991',\n",
       " 'Python',\n",
       " 'Programming',\n",
       " 'was',\n",
       " 'built',\n",
       " 'to',\n",
       " 'give',\n",
       " 'users',\n",
       " 'a',\n",
       " 'easier',\n",
       " 'way',\n",
       " 'of',\n",
       " 'writing',\n",
       " 'code',\n",
       " '.',\n",
       " 'In',\n",
       " 'the',\n",
       " 'Intial',\n",
       " 'day',\n",
       " \"'s\",\n",
       " 'Python',\n",
       " 'was',\n",
       " 'considered',\n",
       " 'a',\n",
       " 'slow',\n",
       " 'programming',\n",
       " 'language',\n",
       " '.',\n",
       " 'Later',\n",
       " 'Many',\n",
       " 'Improvements',\n",
       " 'were',\n",
       " 'made',\n",
       " 'by',\n",
       " 'updating',\n",
       " 'the',\n",
       " 'language',\n",
       " '.',\n",
       " 'And',\n",
       " 'today',\n",
       " 'it',\n",
       " 'has',\n",
       " 'more',\n",
       " 'than',\n",
       " '3',\n",
       " 'lakh',\n",
       " 'librarys',\n",
       " 'available',\n",
       " '.',\n",
       " 'Currently',\n",
       " 'used',\n",
       " 'in',\n",
       " 'Data',\n",
       " 'Related',\n",
       " 'Field',\n",
       " 'Heavily',\n",
       " '.']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786741c7",
   "metadata": {},
   "source": [
    "### Using Sentence Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d502f233",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3949a9c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n    Founded in 1991 Python Programming was built to give users a easier way of writing code.',\n",
       " \"In the Intial day's Python was considered a slow programming language.\",\n",
       " 'Later Many Improvements were made by updating the language.',\n",
       " 'And today it has more than 3 lakh librarys available.',\n",
       " 'Currently used in Data Related Field Heavily.']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3267caef",
   "metadata": {},
   "source": [
    "### Punctuation Removal using RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4394bfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "85bf6e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "regtk = RegexpTokenizer(r'\\w+') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2972deba",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Wow! I am excited to learn NLP !!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "04ce6347",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = regtk.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "89d4c161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wow', 'I', 'am', 'excited', 'to', 'learn', 'NLP']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75ff39b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "601da37c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wow', 'I', 'am', 'excited', 'to', 'learn', 'NLP']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('\\w+', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0e7716",
   "metadata": {},
   "source": [
    "### White Space Tokenizer:\n",
    "\n",
    "    White space tokenizer module of NLTK tokenizes a string on white space (space, tab, newline).\n",
    "    It is an alternate to split()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "135adf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WhitespaceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2c8fed49",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"Good Breads cost Rs 40\\nIn Mumbai. Can you buy me\\ntwo of them\\n\\nThanks.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1423d6a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good Breads cost Rs 40\\nIn Mumbai. Can you buy me\\ntwo of them\\n\\nThanks.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fc1c1cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "wstk = WhitespaceTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bd9fbcb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Good',\n",
       " 'Breads',\n",
       " 'cost',\n",
       " 'Rs',\n",
       " '40',\n",
       " 'In',\n",
       " 'Mumbai.',\n",
       " 'Can',\n",
       " 'you',\n",
       " 'buy',\n",
       " 'me',\n",
       " 'two',\n",
       " 'of',\n",
       " 'them',\n",
       " 'Thanks.']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wstk.tokenize(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c69c063",
   "metadata": {},
   "source": [
    "### DataFrame Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "56a8dc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fdebae89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'Phrases' : [\n",
    "            \"Stay Hungry Stay Foolish\",\n",
    "            \"Faith Can Move Mountains\",\n",
    "            \"The way to get started is to quit talking and begin doing\",\n",
    "            \"If you set your goals ridiculously high and it's a failur, you will fail\",\n",
    "            \"They say dreams do come true but nightmare are also dreams\"\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1406e412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stay Hungry Stay Foolish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Faith Can Move Mountains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The way to get started is to quit talking and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you set your goals ridiculously high and it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>They say dreams do come true but nightmare are...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Phrases\n",
       "0                           Stay Hungry Stay Foolish\n",
       "1                           Faith Can Move Mountains\n",
       "2  The way to get started is to quit talking and ...\n",
       "3  If you set your goals ridiculously high and it...\n",
       "4  They say dreams do come true but nightmare are..."
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5598ff7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tokenize'] = df.apply(lambda x : word_tokenize(x['Phrases']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e5e49b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrases</th>\n",
       "      <th>Tokenize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stay Hungry Stay Foolish</td>\n",
       "      <td>[Stay, Hungry, Stay, Foolish]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Faith Can Move Mountains</td>\n",
       "      <td>[Faith, Can, Move, Mountains]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The way to get started is to quit talking and ...</td>\n",
       "      <td>[The, way, to, get, started, is, to, quit, tal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you set your goals ridiculously high and it...</td>\n",
       "      <td>[If, you, set, your, goals, ridiculously, high...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>They say dreams do come true but nightmare are...</td>\n",
       "      <td>[They, say, dreams, do, come, true, but, night...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Phrases  \\\n",
       "0                           Stay Hungry Stay Foolish   \n",
       "1                           Faith Can Move Mountains   \n",
       "2  The way to get started is to quit talking and ...   \n",
       "3  If you set your goals ridiculously high and it...   \n",
       "4  They say dreams do come true but nightmare are...   \n",
       "\n",
       "                                            Tokenize  \n",
       "0                      [Stay, Hungry, Stay, Foolish]  \n",
       "1                      [Faith, Can, Move, Mountains]  \n",
       "2  [The, way, to, get, started, is, to, quit, tal...  \n",
       "3  [If, you, set, your, goals, ridiculously, high...  \n",
       "4  [They, say, dreams, do, come, true, but, night...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
