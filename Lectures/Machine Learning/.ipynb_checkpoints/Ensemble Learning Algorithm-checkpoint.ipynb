{
 "cells": [
  {
   "cell_type": "raw",
   "id": "83219635",
   "metadata": {},
   "source": [
    "Date - 12/10/2021  11:30 AM to 01:30 PM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e64ecd",
   "metadata": {},
   "source": [
    "# Ensemble Learning Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3974cdfb",
   "metadata": {},
   "source": [
    "    Ensemble model in Machine Learning operate on multiple models to improve the overall performance.\n",
    "    \n",
    "**This can be achieved in various ways:-**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18031633",
   "metadata": {},
   "source": [
    "## 1). Max Voting:\n",
    "\n",
    "    a). The max voting method is generally used for classification problem.\n",
    "    b). In this technique multiple models are used to make predictions for each data points.\n",
    "    c). The prediction by each model are considered as vote.\n",
    "    d). The prediction which we get from the majority of the models are useful as the final prediction.\n",
    "    \n",
    "    Example:- When you ask your friends to suggest you for a mobile phone, there will be multiple options being suggested,\n",
    "                \n",
    "                Friend 1 -> Iphone\n",
    "                Friend 2 -> Oppo\n",
    "                Friend 3 -> One plus\n",
    "                Friend 4 -> One Plus\n",
    "                Friend 5 -> Red Mi\n",
    "                \n",
    "    - In this case the maximum vote is for One Plus hence the decision of purchasing one plus is taken by you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0602308",
   "metadata": {},
   "source": [
    "### Hard Voting Vs Soft Voting\n",
    "\n",
    "**Hard Voting:-**\n",
    "\n",
    "    - In classification a voting ensemble involves making a prediction.\n",
    "    - A Hard voting ensemble involves summing the votes for crisp and labelled data.\n",
    "    - It also involves summing up all the votes and predicting with the most vote.\n",
    "    - Typically used in numerical & categorical data.\n",
    "\n",
    "**Soft Voting:-**\n",
    "\n",
    "    - In soft voting ensemble involves summing up the predicted probablities.\n",
    "    - Typically used in classed labeled data.\n",
    "    - It predicts class with the largest summed of probablity for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa08eab2",
   "metadata": {},
   "source": [
    "### Example : Max Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6707d9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "998ed111",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data[:,1:3]\n",
    "Y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a28c53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3 = KNeighborsClassifier()\n",
    "clf4 = GaussianNB()\n",
    "clf5 = DecisionTreeClassifier(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "527f68af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.95 (+/- 0.04)[Logistic]\n",
      "Accuracy Score: 0.94 (+/- 0.04)[Random Forest]\n",
      "Accuracy Score: 0.95 (+/- 0.04)[KNN]\n",
      "Accuracy Score: 0.91 (+/- 0.04)[Gaussian]\n",
      "Accuracy Score: 0.91 (+/- 0.03)[Decision Tree]\n"
     ]
    }
   ],
   "source": [
    "labels = ['Logistic', 'Random Forest', 'KNN', 'Gaussian' ,'Decision Tree']\n",
    "for clf,label in zip([clf1, clf2, clf3, clf4, clf5], labels):\n",
    "    score = cross_val_score(clf, X, Y, cv=5, scoring='accuracy')\n",
    "    \n",
    "    print(\"Accuracy Score: %0.2f (+/- %0.2f)[%s]\"%(score.mean(), score.std(),label))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37dae716",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf_hard = VotingClassifier(estimators=[\n",
    "    (labels[0],clf1),\n",
    "    (labels[1],clf2),\n",
    "    (labels[2],clf3),\n",
    "    (labels[3],clf4),\n",
    "    (labels[4],clf5)],voting='hard')\n",
    "\n",
    "voting_clf_soft = VotingClassifier(estimators=[\n",
    "    (labels[0],clf1),\n",
    "    (labels[1],clf2),\n",
    "    (labels[2],clf3),\n",
    "    (labels[3],clf4),\n",
    "    (labels[4],clf5)],voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d716b092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.95 (+/- 0.04)[Logistics]\n",
      "Accuracy Score: 0.94 (+/- 0.04)[Random Forest]\n",
      "Accuracy Score: 0.95 (+/- 0.04)[KNN]\n",
      "Accuracy Score: 0.91 (+/- 0.04)[Gaussian]\n",
      "Accuracy Score: 0.91 (+/- 0.03)[Decision Tree]\n",
      "Accuracy Score: 0.95 (+/- 0.04)[Hard Voting]\n",
      "Accuracy Score: 0.95 (+/- 0.04)[Soft Voting]\n"
     ]
    }
   ],
   "source": [
    "labels_new = ['Logistics','Random Forest', 'KNN', 'Gaussian', 'Decision Tree', 'Hard Voting','Soft Voting']\n",
    "for (clf,label) in zip([clf1, clf2, clf3, clf4, clf5, voting_clf_hard, voting_clf_soft],labels_new):\n",
    "    scores = cross_val_score(clf, X, Y, cv=5, scoring='accuracy')\n",
    "    \n",
    "    print(\"Accuracy Score: %0.2f (+/- %0.2f)[%s]\"%(scores.mean(),scores.std(),label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70590e4c",
   "metadata": {},
   "source": [
    "## 2). Averaging:\n",
    "\n",
    "    a). Similar to Max voting technique, multiple predictions are made for each data points in averaging.\n",
    "    b). In this method we take an average of predictions from all the models and use it to make final predicitions.\n",
    "    c). Averaging can be used for making predicitons in regression problem or while calculating the probablities for\n",
    "        classification problems.\n",
    "    \n",
    "    Example:- You have asked for opinion to purchase mobile phone from 5 friends,\n",
    "        \n",
    "                F1 -> IPhone\n",
    "                F2 -> Red Mi\n",
    "                F3 -> One Plus\n",
    "                F4 -> One Plus\n",
    "                F5 -> Oppo\n",
    "                \n",
    "    - Here the average would be take:-\n",
    "    \n",
    "                (1 + 1 + 2 + 1)/5\n",
    "    \n",
    "    - And the final value would be the predictive value for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea16197f",
   "metadata": {},
   "source": [
    "### Example : Average Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04844ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cf61155",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0986c704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2eefeae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bb58d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c0e788c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3 = KNeighborsClassifier()\n",
    "clf4 = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "886801fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.fit(X_train, Y_train)\n",
    "clf2.fit(X_train, Y_train)\n",
    "clf3.fit(X_train, Y_train)\n",
    "clf4.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64e2bcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = clf1.predict_proba(X_test)\n",
    "pred2 = clf2.predict_proba(X_test)\n",
    "pred3 = clf3.predict_proba(X_test)\n",
    "pred4 = clf4.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac5fe8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_pred = (pred1 + pred2 + pred3)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd62e6d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.12350634e-04, 1.04379934e-01, 8.95307715e-01],\n",
       "       [1.03183775e-02, 9.55733646e-01, 3.39479764e-02],\n",
       "       [9.95859921e-01, 4.14003981e-03, 3.89841561e-08],\n",
       "       [5.81762118e-07, 1.26046086e-02, 9.87394810e-01],\n",
       "       [9.88272975e-01, 1.17268379e-02, 1.87143969e-07],\n",
       "       [3.33850649e-03, 1.42575582e-02, 9.82403935e-01],\n",
       "       [9.93268542e-01, 6.73140319e-03, 5.43266375e-08],\n",
       "       [8.99935240e-03, 7.89636846e-01, 2.01363802e-01],\n",
       "       [1.13878420e-03, 4.87553330e-01, 5.11307886e-01],\n",
       "       [1.29232540e-02, 9.66617805e-01, 2.04589406e-02],\n",
       "       [1.89470950e-05, 2.59611312e-02, 9.74019922e-01],\n",
       "       [8.39371275e-03, 8.98879800e-01, 9.27264873e-02],\n",
       "       [1.66164092e-03, 6.97460578e-01, 3.00877781e-01],\n",
       "       [2.36134051e-03, 8.02217537e-01, 1.95421122e-01],\n",
       "       [1.86097274e-03, 7.12657901e-01, 2.85481127e-01],\n",
       "       [9.92359857e-01, 7.64005902e-03, 8.35284249e-08],\n",
       "       [3.65264071e-03, 8.85346997e-01, 1.11000362e-01],\n",
       "       [3.58341073e-03, 8.03657262e-01, 1.92759327e-01],\n",
       "       [9.82693072e-01, 1.73067511e-02, 1.77375724e-07],\n",
       "       [9.95526867e-01, 4.47310009e-03, 3.26798358e-08],\n",
       "       [7.59463584e-04, 3.17245398e-01, 6.81995138e-01],\n",
       "       [4.07300311e-03, 8.99918033e-01, 9.60089642e-02],\n",
       "       [9.71715675e-01, 2.82826457e-02, 1.67908371e-06],\n",
       "       [8.97900633e-01, 1.02099166e-01, 2.00833802e-07],\n",
       "       [1.13878420e-03, 4.87553330e-01, 5.11307886e-01],\n",
       "       [9.96952907e-01, 3.04708426e-03, 8.95498044e-09],\n",
       "       [9.74112620e-01, 1.92196808e-02, 6.66769958e-03],\n",
       "       [6.58361310e-03, 9.43992972e-01, 4.94234150e-02],\n",
       "       [4.17343485e-02, 9.55996984e-01, 2.26866790e-03],\n",
       "       [9.85327046e-01, 1.46726293e-02, 3.25193764e-07],\n",
       "       [3.39422234e-03, 4.09200144e-02, 9.55685763e-01],\n",
       "       [4.07300311e-03, 8.99918033e-01, 9.60089642e-02],\n",
       "       [9.89393413e-01, 1.06064223e-02, 1.65102951e-07],\n",
       "       [9.60770942e-04, 4.67899020e-01, 5.31140209e-01],\n",
       "       [2.44284644e-05, 2.37001453e-02, 9.76275426e-01],\n",
       "       [1.48679316e-02, 9.69865889e-01, 1.52661791e-02],\n",
       "       [9.81015021e-01, 1.23179692e-02, 6.66700989e-03],\n",
       "       [2.76562803e-04, 9.27157365e-02, 9.07007701e-01],\n",
       "       [9.57037467e-03, 9.54412991e-01, 3.60166343e-02],\n",
       "       [1.05421589e-02, 9.61198640e-01, 2.82592011e-02],\n",
       "       [5.36680159e-05, 3.34967023e-02, 9.66449630e-01],\n",
       "       [9.90873994e-01, 9.12592673e-03, 7.93617395e-08],\n",
       "       [3.78292590e-03, 2.22802659e-01, 7.73414415e-01],\n",
       "       [9.86717324e-01, 1.32823889e-02, 2.87145136e-07],\n",
       "       [9.91331755e-01, 8.66811634e-03, 1.28378609e-07]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba86502",
   "metadata": {},
   "source": [
    "## 3). Weighted Average:\n",
    "\n",
    "    a). Weighted Average Technique is an extension of the average method.\n",
    "    b). All models are assigned different weights, defining the importance of each model for prediction.\n",
    "    \n",
    "    - For instance if 4 of your friends have prior experience in using mobile phone and while 3 of them have no prior\n",
    "      experience of using mobile phone.\n",
    "    - In this scenario the opinion of 4 friends who have experience are weighted higher as compared to the rest of the 3.\n",
    "        \n",
    "            F1 - IPhone\n",
    "            F2 - Redmi\n",
    "            F3 - Oppo\n",
    "            F4 - Vivo\n",
    "            F5 - Samsung\n",
    "            F6 - One Plus\n",
    "            F7 - One Plus\n",
    "            \n",
    "                  F1   F2   F3   F4   F5   F6   F7\n",
    "        Weight:  0.23 0.23 0.23 0.23 0.21 0.10 0.10\n",
    "        Rating:   1    2    2    3    4    5    5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffeb6145",
   "metadata": {},
   "source": [
    "### Example : Weighted Avarage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ed8c143",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48baa73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "dtc = DecisionTreeClassifier()\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91c10992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, Y_train)\n",
    "dtc.fit(X_train, Y_train)\n",
    "knn.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6208262",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting = VotingClassifier(estimators=[\n",
    "    ('lr',lr),\n",
    "    ('dtc',dtc),\n",
    "    ('knn',knn)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecb0f0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pred = lr.predict_proba(X_test)\n",
    "dtc_pred = dtc.predict_proba(X_test)\n",
    "knn_pred = knn.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ecd081bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.95 (+/- 0.04)[Logistics]\n",
      "Accuracy Score: 0.95 (+/- 0.04)[KNN]\n",
      "Accuracy Score: 0.91 (+/- 0.03)[Decision Tree]\n",
      "Accuracy Score: 0.95 (+/- 0.04)[Voting]\n"
     ]
    }
   ],
   "source": [
    "labels_new = ['Logistics', 'KNN', 'Decision Tree', 'Voting']\n",
    "for (clf,label) in zip([lr, knn, dtc, voting],labels_new):\n",
    "    scores = cross_val_score(clf, X, Y, cv=5, scoring='accuracy')\n",
    "    \n",
    "    print(\"Accuracy Score: %0.2f (+/- %0.2f)[%s]\"%(scores.mean(),scores.std(),label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5238f93",
   "metadata": {},
   "source": [
    "     Model      Score      Weights\n",
    "     \n",
    "    LogisticR    0.95        0.4\n",
    "      KNN        0.95        0.4\n",
    "    DecisionT    0.93        0.2\n",
    "                           = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1177fc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_avg_pred = (lr_pred*0.4 + dtc_pred*0.2 + knn_pred*0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bff951d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.74820761e-04, 1.13255921e-01, 8.86369258e-01],\n",
       "       [8.38205301e-03, 9.62880375e-01, 2.87375717e-02],\n",
       "       [9.95031905e-01, 4.96804777e-03, 4.67809873e-08],\n",
       "       [6.98114541e-07, 3.12553028e-03, 9.96873772e-01],\n",
       "       [9.85927570e-01, 1.40722055e-02, 2.24572763e-07],\n",
       "       [6.20779225e-06, 9.10906982e-03, 9.90884722e-01],\n",
       "       [9.91922251e-01, 8.07768382e-03, 6.51919650e-08],\n",
       "       [2.79922288e-03, 7.63564215e-01, 2.33636562e-01],\n",
       "       [1.36654104e-03, 4.45063996e-01, 5.53569463e-01],\n",
       "       [1.55079048e-02, 9.59941366e-01, 2.45507288e-02],\n",
       "       [2.27365140e-05, 2.71533574e-02, 9.72823906e-01],\n",
       "       [6.07245530e-03, 8.98655760e-01, 9.52717848e-02],\n",
       "       [1.99396911e-03, 6.76952694e-01, 3.21053337e-01],\n",
       "       [2.83360862e-03, 7.86661045e-01, 2.10505347e-01],\n",
       "       [2.23316729e-03, 6.79189481e-01, 3.18577352e-01],\n",
       "       [9.90831829e-01, 9.16807083e-03, 1.00234110e-07],\n",
       "       [4.38316885e-03, 8.94416396e-01, 1.01200435e-01],\n",
       "       [4.30009287e-03, 8.32388715e-01, 1.63311192e-01],\n",
       "       [9.83231686e-01, 1.67681013e-02, 2.12850868e-07],\n",
       "       [9.94632241e-01, 5.36772011e-03, 3.92158029e-08],\n",
       "       [9.11356301e-04, 2.52694478e-01, 7.46394166e-01],\n",
       "       [4.88760373e-03, 8.95901639e-01, 9.92107570e-02],\n",
       "       [9.66058810e-01, 3.39391748e-02, 2.01490045e-06],\n",
       "       [9.81480759e-01, 1.85189997e-02, 2.41000562e-07],\n",
       "       [1.36654104e-03, 4.45063996e-01, 5.53569463e-01],\n",
       "       [9.96343488e-01, 3.65650111e-03, 1.07459765e-08],\n",
       "       [9.76935144e-01, 2.30636169e-02, 1.23949209e-06],\n",
       "       [7.90033572e-03, 9.32791566e-01, 5.93080980e-02],\n",
       "       [4.60812182e-02, 9.51196380e-01, 2.72240148e-03],\n",
       "       [9.82392455e-01, 1.76071551e-02, 3.90232517e-07],\n",
       "       [7.30668128e-05, 4.11040173e-02, 9.58822916e-01],\n",
       "       [4.88760373e-03, 8.95901639e-01, 9.92107570e-02],\n",
       "       [9.87272095e-01, 1.27277067e-02, 1.98123541e-07],\n",
       "       [1.15292513e-03, 4.17478824e-01, 5.81368251e-01],\n",
       "       [2.93141572e-05, 2.84401744e-02, 9.71530511e-01],\n",
       "       [1.78415180e-02, 9.63839067e-01, 1.83194149e-02],\n",
       "       [9.85218025e-01, 1.47815630e-02, 4.11867954e-07],\n",
       "       [3.31875364e-04, 1.11258884e-01, 8.88409241e-01],\n",
       "       [1.14844496e-02, 9.45295589e-01, 4.32199612e-02],\n",
       "       [1.26505907e-02, 9.61438368e-01, 2.59110413e-02],\n",
       "       [6.44016191e-05, 4.01960428e-02, 9.59739556e-01],\n",
       "       [9.89048793e-01, 1.09511121e-02, 9.52340874e-08],\n",
       "       [5.39511076e-04, 1.99363191e-01, 8.00097298e-01],\n",
       "       [9.84060789e-01, 1.59388667e-02, 3.44574163e-07],\n",
       "       [9.89598106e-01, 1.04017396e-02, 1.54054331e-07]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_avg_pred"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a3c6ba12",
   "metadata": {},
   "source": [
    "Date - 19/10/2021  11:00 AM to 01:00 PM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b3dc05",
   "metadata": {},
   "source": [
    "# Advanced Technique In Ensemble Learning Algorithm\n",
    "\n",
    "## 1) Stacking:-\n",
    "\n",
    "    a). Stacking also known as \"Stacked Generalization\" is an ensemble technique that combines multiple classification or\n",
    "        regression model via meta-classifier or meta-regressor.\n",
    "    b). The base level model are trained on a complete training set then the meta model id trained on the features that are\n",
    "        output of the base level model.\n",
    "    c). The base level often consists of different learning algorithm and therefore stacking algorithm is often\n",
    "        heterogenous(different).\n",
    "\n",
    "**Meta Classifier:-**\n",
    "        \n",
    "    - It is a classifier that makes a final prediciton among all the predictions by using those predictions as a feature.\n",
    "    - It takes classes by various classifiers and pick the final one as the result.\n",
    "        \n",
    "**Meta Regressor:-**\n",
    "        \n",
    "    - Meta regressor is defined to be a meta analysis to combine, compare and synthesize research findings.\n",
    "    - A meta regressor analysis aim to reconcile conflicting studies or colaborate consisting once.\n",
    "    - It combines the data of multiple studies to identify overall trend of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31177e89",
   "metadata": {},
   "source": [
    "## 2) Bagging:-\n",
    "\n",
    "    a). Bagging is an Ensemble Learning technique which aims to reduce the error learning through the implementation of a\n",
    "        set of homogeneous machine learning algorithms.\n",
    "    b). The key idea of bagging is the use of multiple base learners which are trained seperately with a random sample from\n",
    "        the training set, which is through voting or averaging approach which produces more stable and accurate model.\n",
    "\n",
    "**There are 2 main components of bagging technique:-**\n",
    "\n",
    "     i). Random sampling with replacement (bootstraping),\n",
    "    ii). The set of homogeneous machine learning algorithm (ensemble learning)\n",
    "\n",
    "### The bagging process involves the following steps:\n",
    "\n",
    "    1). It is extracted \"n\" subsets from the training set,\n",
    "    2). These subsets are use to train \"n\" base learners of same type,\n",
    "    3). For making predictions each one of the \"n\" learners are feed with the test sample,\n",
    "    4). The output of each learner is averaged (in case of regression) or voted (in case of classification).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539da361",
   "metadata": {},
   "source": [
    "### Example : Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26174f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b891a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = load_breast_cancer(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af33a75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4de9880f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "34e9106c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3c57700",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=3, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "508a3caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging = BaggingClassifier(base_estimator=tree, n_estimators=5, max_samples=50, bootstrap=True)\n",
    "\n",
    "# base_estimator : Decision Tree,\n",
    "# n_estimators   : It will create 5 subsets to train 5 Decision Tree Models,\n",
    "# max_samples    : It will take randomly 50 items with replacement,\n",
    "# bootstrap      : It means that the sample will be a replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ec31fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=3,\n",
       "                                                        random_state=23),\n",
       "                  max_samples=50, n_estimators=5)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e366c883",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Accuracy : 0.9366197183098591\n",
      "Testing Data Accuracy : 0.9440559440559441\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Data Accuracy :\", bagging.score(x_train, y_train))\n",
    "print(\"Testing Data Accuracy :\", bagging.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "712478b5",
   "metadata": {},
   "source": [
    "Date - 20/10/2021  11:30 AM to 01:30 PM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44abc4b",
   "metadata": {},
   "source": [
    "## 3) Boosting:-\n",
    "\n",
    "    a). Boosting is an Ensemble Learning Technique similar to bagging.\n",
    "    b). It typically makes use of base learners to imporve the stability and effectiveness of a ML model.\n",
    "    c). The main concept behind a boosting technique is the generation of sequential hypotheses, where each hypothesis\n",
    "        tries to improve or correct the mistake (error) made.\n",
    "    d). The main idea of boosting is the implementation of homogeneous ML algorithm in a sequential way, where each of\n",
    "        these ML algorithm tries to improve the stability of the model by focusing on the error made by previous Machine\n",
    "        Learning Algorithm.\n",
    "    e). The process in which the error of each base learner is considered to be improved with the next base learner in the\n",
    "        sequence is the key for boosting technique.\n",
    "        \n",
    "**Most commonly type of boosting technique used are:-**\n",
    "\n",
    "     i). ADA Boost (Adaptive Boosting),\n",
    "    ii). Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204c8736",
   "metadata": {},
   "source": [
    "## ADAPTIVE BOOSTING:\n",
    "\n",
    "    1). AdaBoost is a algorithm based on the boosting technique.\n",
    "    2). AdaBoost implements a vector of weight to penalize those samples that were incorrectly predicted (by increasing the\n",
    "        weight) and reward those that were correctly predicted (by decreasing their weight).\n",
    "    3). Each base learner in the sequence will have assigned a weight the higher the performance the heigher the weight and\n",
    "        greater the impact of this base learner for the final decision.\n",
    "    4). To make prediction each base learner in the sequence will be fed with test data, each of prediction will be voted\n",
    "        (for classification) OR averaged (in case of regression)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab4eadf",
   "metadata": {},
   "source": [
    "### Example : ADA Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "516154f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fcf0aaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e57ceda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "75adfde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "35164f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c1ce333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "68366aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.2, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "237720d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f967b135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 4)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "18af349e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating ADA BOOST Model\n",
    "\n",
    "AdaModel = AdaBoostClassifier(n_estimators=100, learning_rate=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f428f899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(learning_rate=1, n_estimators=100)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AdaModel.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "598c35e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = AdaModel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b5fe865a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 0, 2, 1, 0, 2, 0, 1, 1, 0, 2, 0, 0, 2, 1, 1, 2, 0, 2, 0,\n",
       "       0, 0, 2, 0, 0, 2, 1, 1])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c24813db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 0, 2, 1, 0, 2, 0, 1, 1, 0, 2, 0, 0, 1, 1, 1, 2, 0, 2, 0,\n",
       "       0, 0, 2, 0, 0, 2, 1, 1])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3719a9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy is:\",accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990446eb",
   "metadata": {},
   "source": [
    "#### using Support Vector Machine model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "08c1c2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1287e68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(probability=True, kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1daea670",
   "metadata": {},
   "outputs": [],
   "source": [
    "adb = AdaBoostClassifier(base_estimator=svc, n_estimators=100, learning_rate=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d527583b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=SVC(kernel='linear', probability=True),\n",
       "                   learning_rate=1, n_estimators=100)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adb.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1475de74",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred1 = adb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0b873b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SVC Accuracy is: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"Using SVC Accuracy is:\",accuracy_score(Y_test, Y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3902da",
   "metadata": {},
   "source": [
    "## GRADIENT BOOSTING:\n",
    "\n",
    "    1). The Gradient boosting method does not implement a vector of weights like Adaboost does.\n",
    "    2). As the name implies, it does the calculation of the gradient for the optimization of the model.\n",
    "    3). Each base learner added to the sequence will minimize the residuals (errors) determined by the previous base\n",
    "        learners.\n",
    "    4). To make prediction each base learner in the sequence will be fed with test data, each of prediction will be voted\n",
    "        (for classification) OR averaged (in case of regression)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650dfdb3",
   "metadata": {},
   "source": [
    "### Example : Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c349f151",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "396bad1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = load_breast_cancer(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d2835a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c84dee4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569,)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f12b9d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train, X_Test, Y_Train, Y_Test = train_test_split(X, Y, test_size=0.25, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8eae3c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 30)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b758a67b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143, 30)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0692059e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbmodel = GradientBoostingClassifier(n_estimators=5, learning_rate=1, max_depth=2,random_state=30)\n",
    "\n",
    "# base learning algorithm is Decision Tree by default\n",
    "# n_estimator is the number of subset\n",
    "# depth for each decision tree is 2\n",
    "# learning rate for each estimator in the sequence is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a4bd27c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=1, max_depth=2, n_estimators=5,\n",
       "                           random_state=30)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbmodel.fit(X_Train, Y_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1782aa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_Pred = gbmodel.predict(X_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2cc55ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9370629370629371\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score:\",accuracy_score(Y_Test, Y_Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ac6d3263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,  0,\n",
       "        0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  1, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "       -1,  0,  0,  0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_Test - Y_Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5c2accaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0601583d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[46,  6],\n",
       "       [ 3, 88]], dtype=int64)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_Test, Y_Pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f2fa34b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.88      0.91        52\n",
      "           1       0.94      0.97      0.95        91\n",
      "\n",
      "    accuracy                           0.94       143\n",
      "   macro avg       0.94      0.93      0.93       143\n",
      "weighted avg       0.94      0.94      0.94       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_Test, Y_Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a19082be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_Train - gbmodel.predict(X_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2e2cd24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[158,   2],\n",
       "       [  1, 265]], dtype=int64)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_Train, gbmodel.predict(X_Train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "39c86f08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       160\n",
      "           1       0.99      1.00      0.99       266\n",
      "\n",
      "    accuracy                           0.99       426\n",
      "   macro avg       0.99      0.99      0.99       426\n",
      "weighted avg       0.99      0.99      0.99       426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_Train, gbmodel.predict(X_Train)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
