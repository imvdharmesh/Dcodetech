{
 "cells": [
  {
   "cell_type": "raw",
   "id": "15ad283e",
   "metadata": {},
   "source": [
    "Date - 22/10/2021  11:00 AM to 01:00 PM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc58b6c7",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "\n",
    "    - Stemming is the preocess of removing a part of word or reducing a word to its stem or root.\n",
    "    - A stemming algorithm reduces the word.\n",
    "    \n",
    "    For Example : \"chocolates\", \"chocolaty\", \"choco\"   \n",
    "      \n",
    "    When you apply the stemming concept the words are reduced to its root/stem (in the above example the word \"choco\" will\n",
    "    be the root word).\n",
    "\n",
    "\n",
    "### Over Stemming:\n",
    "\n",
    "    Over stemming is the process where a much larger part of word is chopped off (removed) than what is required, which in\n",
    "    turn leads to two or more words being reduced to the same root word or stem incorrectly when they should have been\n",
    "    reduced to two or more stem words.\n",
    "\n",
    "    For Example: \"universal\", \"university\", \"universe\" ==> \"univers\"\n",
    "\n",
    "\n",
    "### Under Stemming:\n",
    "\n",
    "    Under stemming is when two words that should be stemmed to the same root are not being done. This is also known as\n",
    "    false negative.\n",
    "    \n",
    "    For Example: \"alumnus\", \"alumni\", \"alumnae\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c180b78f",
   "metadata": {},
   "source": [
    "### Porter Stemmer Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73f82f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4e75982",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b0b2b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3c0e58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = [\"program\", \"programmer\", \"programs\", \"programming\", \"programmers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6d52f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "program   program\n",
      "programmer   programm\n",
      "programs   program\n",
      "programming   program\n",
      "programmers   programm\n"
     ]
    }
   ],
   "source": [
    "for item in word:\n",
    "    print(item,\" \", ps.stem(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7e564ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Provision Maximum multiple owned caring on go gone going was this\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "329756c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tk_list = word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36fa9c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Provision',\n",
       " 'Maximum',\n",
       " 'multiple',\n",
       " 'owned',\n",
       " 'caring',\n",
       " 'on',\n",
       " 'go',\n",
       " 'gone',\n",
       " 'going',\n",
       " 'was',\n",
       " 'this']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21b78e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provision   provis\n",
      "Maximum   maximum\n",
      "multiple   multipl\n",
      "owned   own\n",
      "caring   care\n",
      "on   on\n",
      "go   go\n",
      "gone   gone\n",
      "going   go\n",
      "was   wa\n",
      "this   thi\n"
     ]
    }
   ],
   "source": [
    "for word in tk_list:\n",
    "    print(word, \" \", ps.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db918a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generous   gener\n",
      "generate   gener\n",
      "generously   gener\n",
      "generation   gener\n"
     ]
    }
   ],
   "source": [
    "words = ['generous','generate','generously','generation']\n",
    "for word in words:\n",
    "    print(word,\" \",ps.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99847440",
   "metadata": {},
   "source": [
    "### Snowball Stemmer Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae46e2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfaf2adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowball = SnowballStemmer(language=\"german\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "832dc5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = [\"program\", \"programmer\", \"programs\", \"programming\", \"programmers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6b42cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "program   program\n",
      "programmer   programm\n",
      "programs   program\n",
      "programming   programming\n",
      "programmers   programm\n"
     ]
    }
   ],
   "source": [
    "for item in word:\n",
    "    print(item,\" \", snowball.stem(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1af7218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provision   provision\n",
      "Maximum   maximum\n",
      "multiple   multipl\n",
      "owned   owned\n",
      "caring   caring\n",
      "on   on\n",
      "go   go\n",
      "gone   gon\n",
      "going   going\n",
      "was   was\n",
      "this   this\n"
     ]
    }
   ],
   "source": [
    "for item in tk_list:\n",
    "    print(item,\" \", snowball.stem(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a20f6654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generous   generous\n",
      "generate   generat\n",
      "generously   generously\n",
      "generation   generation\n"
     ]
    }
   ],
   "source": [
    "for item in words:\n",
    "    print(item,\" \", snowball.stem(item))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c3894d",
   "metadata": {},
   "source": [
    "### Lancaster Stemmer Algorithm\n",
    "\n",
    "    Lancaster stemmer is simple but it tends to produce results with over stemming Over stemming causes the stem to be non\n",
    "    meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "706705ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "970ba4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "lancaster = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e194c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "program   program\n",
      "programmer   program\n",
      "programs   program\n",
      "programming   program\n",
      "programmers   program\n"
     ]
    }
   ],
   "source": [
    "for item in word:\n",
    "    print(item,\" \", lancaster.stem(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb0121ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provision   provid\n",
      "Maximum   maxim\n",
      "multiple   multipl\n",
      "owned   own\n",
      "caring   car\n",
      "on   on\n",
      "go   go\n",
      "gone   gon\n",
      "going   going\n",
      "was   was\n",
      "this   thi\n"
     ]
    }
   ],
   "source": [
    "for item in tk_list:\n",
    "    print(item,\" \", lancaster.stem(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c90d67d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generous   gen\n",
      "generate   gen\n",
      "generously   gen\n",
      "generation   gen\n"
     ]
    }
   ],
   "source": [
    "for item in words:\n",
    "    print(item,\" \", lancaster.stem(item))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e159779c",
   "metadata": {},
   "source": [
    "## Lemmatization\n",
    "\n",
    "    - Lemmatization is the process of converting a word to its base form.\n",
    "    - The difference between Stemming and Lemmatization is lemmatization considers the context & converts the word into a\n",
    "      meaningful base form whereas stemming just removes the last few characters often leading to incorrect & spelling\n",
    "      errors.\n",
    "    \n",
    "    For Example:-   'Caring' => Lemmatization => 'Care'\n",
    "                    'Caring' => Stemming => 'Car'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3033bf9a",
   "metadata": {},
   "source": [
    "**Some lemmatization libraries**\n",
    "\n",
    "    - word lemmatizer,\n",
    "    - spacy lemmatizer,\n",
    "    - textblob,\n",
    "    - clip pattern,\n",
    "    - stanford coreNLP,\n",
    "    - Genism Lemmatizer,\n",
    "    - TreeTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16b92fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a0c9582",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Abhi\n",
      "[nltk_data]     Kumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "73576948",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "69d6ed7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "acbbb9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['bats', 'are', 'feet', 'hands']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "167df30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bats   bat\n",
      "are   are\n",
      "feet   foot\n",
      "hands   hand\n"
     ]
    }
   ],
   "source": [
    "# lemmatization\n",
    "\n",
    "for item in words:\n",
    "    print(item,\" \",lemmatizer.lemmatize(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e42da014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bats   bat\n",
      "are   ar\n",
      "feet   feet\n",
      "hands   hand\n"
     ]
    }
   ],
   "source": [
    "# lancaster stemming\n",
    "\n",
    "for item in words:\n",
    "    print(item,\" \",lancaster.stem(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "910e2241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bats   bat\n",
      "are   are\n",
      "feet   feet\n",
      "hands   hand\n"
     ]
    }
   ],
   "source": [
    "# snowball stemming\n",
    "\n",
    "for item in words:\n",
    "    print(item,\" \",snowball.stem(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "39f940b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bats   bat\n",
      "are   are\n",
      "feet   feet\n",
      "hands   hand\n"
     ]
    }
   ],
   "source": [
    "# porter stemming\n",
    "\n",
    "for item in words:\n",
    "    print(item,\" \",ps.stem(item))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed28ff73",
   "metadata": {},
   "source": [
    "### Sentence Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0fc6d63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The striped bats are hanging on their feet for best\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3a1f526f",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = nltk.word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2fe112d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'striped',\n",
       " 'bats',\n",
       " 'are',\n",
       " 'hanging',\n",
       " 'on',\n",
       " 'their',\n",
       " 'feet',\n",
       " 'for',\n",
       " 'best']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1dd575c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_output = ' '.join([lemmatizer.lemmatize(item) for item in word_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "176fe213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The striped bat are hanging on their foot for best\n"
     ]
    }
   ],
   "source": [
    "print(lemmatized_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e32ba274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The striped bats are hanging on their feet for best\n"
     ]
    }
   ],
   "source": [
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1377bb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strip\n"
     ]
    }
   ],
   "source": [
    "# for converting the lemmatize word into verb (POS)\n",
    "\n",
    "print(lemmatizer.lemmatize('stripes','v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "40d97c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stripe\n"
     ]
    }
   ],
   "source": [
    "# for converting the lemmatize word into noun (POS)\n",
    "\n",
    "print(lemmatizer.lemmatize('stripes','n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8f274c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can't can't\n",
      "what's what's\n",
      "couldn't couldn't\n",
      "wasn't wasn't\n"
     ]
    }
   ],
   "source": [
    "print(\"can't\",lemmatizer.lemmatize(\"can't\"))\n",
    "print(\"what's\",lemmatizer.lemmatize(\"what's\"))\n",
    "print(\"couldn't\",lemmatizer.lemmatize(\"couldn't\"))\n",
    "print(\"wasn't\",lemmatizer.lemmatize(\"wasn't\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
